{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(columns=['EIN','NAME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_unique = application_df.dtypes.index.tolist()\n",
    "application_df[application_unique].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T14        3\n",
       "T25        3\n",
       "T15        2\n",
       "T29        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_value = application_df.loc[:, 'APPLICATION_TYPE'].value_counts()\n",
    "application_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(application_value[application_value<200].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C8210        1\n",
       "C1732        1\n",
       "C1245        1\n",
       "C2170        1\n",
       "C1900        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_value = application_df.loc[:, 'CLASSIFICATION'].value_counts()\n",
    "classification_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD5CAYAAADx05gdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuu0lEQVR4nO3de5Rd5X3f//d3ztzvV90FEpa4SLGxQZGdOnbdkAThtFZSQy3aOJhCSR1Y/tVZv6bQdlH/aFi/kK7+3NiGuMSQYOpVQajjjh0l1ATHdnwBBttgJCyYSAJd0WiuGs195vv7Yz9ndDScM3Nm5uxz5hx9XmsdZp9nP/vZzz46zHeey362uTsiIiJxKit0BUREpPQp2IiISOwUbEREJHYKNiIiEjsFGxERiZ2CjYiIxK48zsLNbBfwR0AC+JK7/8Gc/VXAl4FrgV7gY+5+JOy7B7gNmAY+5e5PZ1nm54B/6e71C50jk/b2dt+0adOSr1tE5GL04osvnnH3jnT7Ygs2ZpYAHgR+BTgGvGBmne5+ICXbbUC/u28xsz3AA8DHzGwbsAfYDqwDnjGzy8MxGcs0sx1Ay5yqpD3HfHXftGkTXV1dS752EZGLkZm9kWlfnN1oO4Fudz/k7hPAXmD3nDy7gcfC9lPAdWZmIX2vu4+7+2GgO5SXscwQ3P4L8HtZnkNERPIkzmCzHjia8v5YSEubx92ngEGgbZ5j5yvzLqDT3U9meQ4REcmTWMds8sXM1gE3AR9aRhl3AHcAXHLJJbmpmIiIAPG2bI4DG1PebwhpafOYWTnQRDSIn+nYTOnvAbYA3WZ2BKg1s+4FznEBd3/Y3Xe4+46OjrTjWyIiskRxBpsXgK1mttnMKokG/Dvn5OkEbgnbNwLPerQyaCewx8yqzGwzsBV4PlOZ7v6X7r7G3Te5+yZgxN23LHAOERHJk9i60dx9yszuAp4mmqb8qLvvN7P7gC537wQeAR4PrZA+ouBByPckcACYAu5092mAdGUuUJW05xARkfwx/ZH/djt27HBNfRYRWRwze9Hdd6TbpxUEpGCmZ5wnu47yw0NvG0ITkRJTErPRpDj92feP8J+/cYAyg6f/zQfZurqh0FUSkZioZSMFMT3j/On3DrNlVT3lZWV85bk3C10lEYmRgo0UxKsnhzjWP8on/+E7+OVtq/jGyyfR+KFI6VKwkYJIjtO8f0s7v7ilgzPD4xw+c67AtRKRuCjYSEE8d7iPTW21rGmqZufmaO3UF470FbhWIhIXBRspiFdPDvFz65sAeEdHPfVV5ew/MVTgWolIXBRsJO+GxiY51j/KVWsbATAzLl9dz89OnS1wzUQkLgo2knevhaBy5ZrzU52vWNPIwVNnNUlApEQp2EjeHeqJJgJsWVU/m3bF6noGRyfpOTteqGqJSIwUbCTv3ug7R6LMWNdcM5t2aXsdAG/2jRSqWiISIwUbybs3+0ZZ11xNReL81++S1tqwT8FGpBQp2Ejevdl7jktb6y5I29BSg5mCjUipUrCRvHujb4RL2movSKsqT7C2sVrBRqREKdhIXg2OTjIwMjnbbZZqY2stRxVsREqSgo3kVTKYpAs2l7TWqmUjUqIUbCSvTg6OAVwwEy1pY2stbw2NMz41ne9qiUjMYg02ZrbLzA6aWbeZ3Z1mf5WZPRH2P2dmm1L23RPSD5rZ9QuVaWaPmNlLZvaymT1lZvUh/RNm1mNmPwmv2+O8ZpnfqaEo2Kxtqn7bvjWNUdrpId1rI1JqYgs2ZpYAHgRuALYBN5vZtjnZbgP63X0L8FnggXDsNmAPsB3YBTxkZokFyvy0u1/t7u8C3gTuSjnPE+7+7vD6UhzXK9k5NThKosxor6962741IQAlA5KIlI44WzY7gW53P+TuE8BeYPecPLuBx8L2U8B1ZmYhfa+7j7v7YaA7lJexTHcfAgjH1wBa92QFOjU4zqqGKhJl9rZ9yWCT7GoTkdIRZ7BZDxxNeX8spKXN4+5TwCDQNs+x85ZpZn8KnAKuBD6fku+jKd1rG9NV1szuMLMuM+vq6enJ+iJlcd4aGmN149u70OB8sHlLwUak5JTUBAF3vxVYB7wKfCwkfx3YFLrXvsn5ltTcYx929x3uvqOjoyMv9b0YnRoamx2bmauhqpzayoRaNiIlKM5gcxxIbUVsCGlp85hZOdAE9M5z7IJluvs0UffaR8P7XndPjjh/Cbh2yVcky3ZqcGy2BTOXmbGmsZq3NGYjUnLiDDYvAFvNbLOZVRIN+HfOydMJ3BK2bwSe9WiN+U5gT5itthnYCjyfqUyLbIHZMZuPAD8L79emnO8jRK0eKYDh8SmGx6cyBhuIutI0QUCk9JTHVbC7T5nZXcDTQAJ41N33m9l9QJe7dwKPAI+bWTfQRxQ8CPmeBA4AU8CdocVChjLLgMfMrBEw4CXgk6EqnzKzj4Ry+oBPxHXNMr/TIYisbnz7TLSkNY3VPHdYj4cWKTWxBRsAd98H7JuTdm/K9hhwU4Zj7wfuz7LMGeD9Gcq5B7hnsXWX3DszPAGQdtpzUkdjFT1nx3F3okaqiJSCkpogICtb73A0dNZWlznYtNdVMTE9w9DYVL6qJSJ5oGAjeXPmXGjZNFRmzJPcd2ZYqwiIlBIFG8mbZMumtXaeYBO62M7o8dAiJUXBRvLmzPA4LbUVlCcyf+1mg00Y3xGR0qBgI3nTOzxB2zyTAyA12KhlI1JKFGwkb3qHJ2ivz9yFBtBaV0mZKdiIlBoFG8mbM+fGF2zZJMqM1rpKdaOJlBgFG8mb3uEJ2uvmb9lA1JWmlo1IaVGwkbyYmJphcHRy3hs6kxRsREqPgo3kRV+4x2ahbjSA9vpKBRuREqNgI3mRDB5tC0wQiPJUceasxmxESomCjeRFb3L1gCyCTXt9FaOT05wb15I1IqVCwUbyIrkiQHZjNlqyRqTUKNhIXvSeS3ajLRxsWsOMtf6RyVjrJCL5o2AjedE7PEFVeRl1lYkF87Ykg805jduIlAoFG8mLM8MTtNdXZfWMmuRCnX0KNiIlI9ZgY2a7zOygmXWb2d1p9leZ2RNh/3Nmtill3z0h/aCZXb9QmWb2iJm9ZGYvm9lTZla/0Dkkf/pHJmipq8gq72zLZkTBRqRUxBZszCwBPAjcAGwDbjazbXOy3Qb0u/sW4LPAA+HYbUSPiN4O7AIeMrPEAmV+2t2vdvd3AW8Cd813Dsmv/pEJWuZ5tECqxupyEmWmlo1ICYmzZbMT6Hb3Q+4+AewFds/Jsxt4LGw/BVxnUT/LbmCvu4+7+2GgO5SXsUx3HwIIx9cAvsA5JI8GRiZpzjLYmBkttZVq2YiUkDiDzXrgaMr7YyEtbR53nwIGgbZ5jp23TDP7U+AUcCXw+QXOIXk0MDJBc0123WgArXUV9J/TbDSRUlFSEwTc/VZgHfAq8LHFHGtmd5hZl5l19fT0xFK/i9XMjDM4OklLbfbBpqW2kj61bERKRpzB5jiwMeX9hpCWNo+ZlQNNQO88xy5YprtPE3WvfXSBczDnuIfdfYe77+jo6Mj6ImVhQ2OTzDhZd6NBdK+Npj6LlI44g80LwFYz22xmlUQD/p1z8nQCt4TtG4Fn3d1D+p4wk2wzsBV4PlOZFtkCs2M2HwF+tsA5JE+SN2dmOxstyqsxG5FSUh5Xwe4+ZWZ3AU8DCeBRd99vZvcBXe7eCTwCPG5m3UAfUfAg5HsSOABMAXeGFgsZyiwDHjOzRsCAl4BPhqqkPYfkz0AIGs01i2jZ1FbSPzLJzIxTVqb5HCLFLrZgA+Du+4B9c9LuTdkeA27KcOz9wP1ZljkDvD9DORnPIfkxEFo2zYsZs6mrZHrGOTs2RdMijhORlamkJgjIypTsDsv2PpsobxRgNElApDQo2EjsZsdsFhNs6rRkjUgpUbCR2A2MTFBm0FCdfa9tcn00zUgTKQ0KNhK7gZFJmmoqFjXQn3zMgLrRREqDgo3EbjHroiXpMQMipUXBRmI3MDK56BlldZUJKhNleoCaSIlQsJHYLaVlY2a01FWoZSNSIhRsJHbRis+Lv1dG66OJlA4FG4ndwBJaNqD10URKiYKNxGpiaoZzE9OLerxAUkudWjYipULBRmI1uy5a3RJaNrWVuqlTpEQo2EisBkaTqwcsZcymgsHRSaZntEi3SLFTsJFYJcdcljJm01xbiTsMjWr6s0ixU7CRWCXvk2lawpiNVhEQKR0KNhKr5JhNyxLGbJLTpQcUbESKnoKNxGp5YzbJJWvUjSZS7BRsJFb9IxNUlpdRU5FY9LHqRhMpHbEGGzPbZWYHzazbzO5Os7/KzJ4I+58zs00p++4J6QfN7PqFyjSzr4T0V8zsUTOrCOkfMrNBM/tJeN2L5M3AuUmaayowW/yjndWNJlI6Ygs2ZpYAHgRuALYBN5vZtjnZbgP63X0L8FnggXDsNmAPsB3YBTxkZokFyvwKcCXwTqAGuD3lPN9193eH1325v1rJZCnroiXVV5VTkTAtxilSAuJs2ewEut39kLtPAHuB3XPy7AYeC9tPAddZ9CfwbmCvu4+7+2GgO5SXsUx33+cB8DywIcZrkywNjC5tXTSIFuNsrtWSNSKlIM5gsx44mvL+WEhLm8fdp4BBoG2eYxcsM3SffRz465TkXzCzl8zsr8xse7rKmtkdZtZlZl09PT3ZXaEsaKnroiW11FbQr240kaJXihMEHgK+4+7fDe9/BFzq7lcDnwe+lu4gd3/Y3Xe4+46Ojo781PQi0L/EFZ+TWmorNRtNpATEGWyOAxtT3m8IaWnzmFk50AT0znPsvGWa2X8COoDfTaa5+5C7D4ftfUCFmbUv58IkO+7OwMgEzctq2VSqZSNSAuIMNi8AW81ss5lVEg34d87J0wncErZvBJ4NYy6dwJ4wW20zsJVoHCZjmWZ2O3A9cLO7zyRPYGZrwjgQZraT6Jp7Y7liucDIxDST076ke2ySWuoqNEFApASUx1Wwu0+Z2V3A00ACeNTd95vZfUCXu3cCjwCPm1k30EcUPAj5ngQOAFPAne4+DZCuzHDKLwJvAD8IseWrYebZjcAnzWwKGAX2hIAmMUu2SJbbjTYwMoG7L2n6tIisDLEFG5jttto3J+3elO0x4KYMx94P3J9NmSE97bW4+xeALyyq4pITA6FFstxutKkZ5+z4FI3VSw9aIlJYpThBQFaIZMtmWbPRwioCA5okIFLUFGwkNsmWzbLGbMKxWrJGpLgp2EhsksvMNC0j2CS74DQjTaS4KdhIbGbHbGqW3o2WXIxTqwiIFDcFG4lN/8gk9VXlVJYv/WuW7EbT9GeR4qZgI7EZGJ1Y0hM6UzVWV1BmWvlZpNhlFWzM7Ktm9mtmpuAkWRsYmaSlbnnBpqwsWoyzT91oIkUt2+DxEPDPgdfN7A/M7IoY6yQlYmBkYlnjNUnNtRWz4z8iUpyyCjbu/oy7/wvgGuAI8IyZfd/Mbk0+pExkroFlLsKZ1KqWjUjRy7pbzMzagE8QPZTsx8AfEQWfb8ZSMyl6y3mWTapmLcYpUvSyWq7GzP4CuAJ4HPgn7n4y7HrCzLriqpwUr5kZX/azbJJaait45bi60USKWbZro/1JWJNslplVhSdp7oihXlLkzo5PMeMsezYaRPfa9GkxTpGilm032u+nSftBLisipWUgB+uiJTXXVjIxNcPo5PSyyxKRwpi3ZWNma4geu1xjZu8Bkn9WNgK1MddNitj5FZ+X37JJvbGztjLWhcpFJCYL/Z97PdGkgA3A/5eSfhb49zHVSUrA+WfZ5GDMJmXJmvXNNcsuT0Tyb95g4+6PAY+Z2Ufd/X/lqU5SAgZHc9my0WKcIsVu3jEbM/vNsLnJzH537muhws1sl5kdNLNuM7s7zf4qM3si7H/OzDal7LsnpB80s+sXKtPMvhLSXzGzR5P3/1jkcyH/y2Z2zcIfiyxXcuHMXIzZtIZVCHSvjUjxWmiCQF34WQ80pHllZGYJ4EHgBmAbcLOZbZuT7Tag3923AJ8FHgjHbiN6RPR2YBfwkJklFijzK8CVwDuBGqL7gQh5t4bXHcAfL3DNkgMDoWXTWL38MZZkV5xWERApXgt1o/338PP/WULZO4Fudz8EYGZ7gd3AgZQ8u4HPhO2ngC9YNLd1N7DX3ceBw2bWHcojU5mpU7PN7HmicabkOb7s7g780MyazWxtyr1CEoOBkUkaq8spTyx/Ob3mmuQEAbVsRIpVtgtx/qGZNZpZhZn9jZn1pHSxZbIeOJry/lhIS5vH3aeAQaBtnmMXLDN0n30c+OtF1ENybGBkIieTAwDKE2U0VpfrmTYiRSzbPzt/1d2HgH9MtDbaFuDfxlWpZXoI+I67f3cxB5nZHWbWZWZdPT09MVXt4tE/Mrmsx0HP1VJXqWfaiBSxbINNsrvt14A/d/fBLI45DmxMeb8hpKXNY2blQBPQO8+x85ZpZv8J6ABSJy9kUw/c/WF33+HuOzo6OrK4PJnPwOgkTTlq2YDWRxMpdtkGm2+Y2c+Aa4G/MbMOYGyBY14AtprZZjOrJBrw75yTpxO4JWzfCDwbxlY6gT1httpmosH95+cr08xuJ7ov6GZ3n5lzjt8Ks9LeBwxqvCZ+0bpouWvZtNZWKNiIFLGspgq5+91m9odEv6inzewc0cD7fMdMmdldwNNAAnjU3feb2X1Al7t3Ao8Aj4cJAH1EwYOQ70miyQRTwJ3uPg2Qrsxwyi8CbwA/COtnfdXd7wP2AR8GuoER4NZsrlmWZ2BkcnZgPxdaait57a3hnJUnIvm1mHmpVxLdb5N6zJfnOyDMENs3J+3elO0x4KYMx94P3J9NmSE97bWEltKd89VTcmt6xhkam8zZBAFIjtmoZSNSrLJ9xMDjwDuAnwDJ1RCdBYKNXJyGRidxz83qAUkttRWMTEwzPjVNVXkiZ+WKSH5k27LZAWwLrQSReSVv6MzF6gFJqTd2rm5UsBEpNtlOEHgFWBNnRaR0JLu7mnI5QSAsxqkla0SKU7Ytm3bgQLgzfzyZ6O4fiaVWUtQGR+Jo2WgVAZFilm2w+UyclZDSMvt4gRzPRgOtjyZSrLKd+vxtM7sU2Oruz5hZLdHUY5G3GYihZaNuNJHilu3aaP+KaKHM/x6S1gNfi6lOUuQGRiYoM2jIwYrPSclutAF1o4kUpWwnCNwJvB8YAnD314FVcVVKitvA6CRNNRWUldnCmbNUVZ6grjJB3zl1o4kUo2yDzbi7z/5JGW7s1DRoSat/JLc3dCY111aqZSNSpLINNt82s38P1JjZrwB/Dnw9vmpJMYseL5C7yQFJLXVaH02kWGUbbO4GeoCfAr9NtFzMf4yrUlLccr0uWlJLbSV9mo0mUpSynY02Y2ZfA77m7nrYi8yr79wEW1fV57zcltpK3uwbyXm5IhK/eVs2YVn+z5jZGeAgcDA8pfPe+Y6Ti1v/yMTsVOVcaqmt0NM6RYrUQt1onyaahfbz7t7q7q3Ae4H3m9mnY6+dFJ2xyWlGJqZprY8h2NRVMjQ2xdT0zMKZRWRFWSjYfJzoYWSHkwnufgj4TeC34qyYFKfkTZetMcxGm11FYFTjNiLFZqFgU+HuZ+YmhnGb3I8AS9GbDTZxdKOFMtWVJlJ8Fgo28/1frf/j5W3iDDbJ1pKWrBEpPgsFm6vNbCjN6yzwzoUKN7NdZnbQzLrN7O40+6vM7Imw/zkz25Sy756QftDMrl+oTDO7K6S5mbWnpH/IzAbN7CfhpckNMYoz2LSFcaAzwwo2IsVm3qnP7r7kxTbNLAE8CPwKcAx4wcw63f1ASrbbgH5332Jme4AHgI+Z2TZgD7AdWAc8Y2aXh2Mylfk94BvA36apznfd/R8v9Voke3EGm/b6KgDODI8vkFNEVppsb+pcip1At7sfCkvd7AV2z8mzG3gsbD8FXGdmFtL3uvt4mJzQHcrLWKa7/9jdj8R4PZKFvnMTJMqMxurcD+m11lVSZtCrYCNSdOIMNuuBoynvj4W0tHncfQoYBNrmOTabMtP5BTN7ycz+ysy2p8tgZneYWZeZdfX06L7Vpeo9N0FLbWVOF+FMSpQZrXWV9KgbTaToxBlsVoofAZe6+9XA58nwaAR3f9jdd7j7jo6OjnzWr6T0n5ugtS6+iYptdVXqRhMpQnEGm+PAxpT3G0Ja2jxhJekmoHeeY7Mp8wLuPuTuw2F7H1CROoFAcqvvXDyrByS1N1Qq2IgUoTiDzQvAVjPbbGaVRAP+nXPydAK3hO0bgWfd3UP6njBbbTOwFXg+yzIvYGZrwjgQZraT6Jp7c3KF8jZ9MS1Vk9Rer5aNSDHK3aMU53D3KTO7C3ia6BHSj7r7fjO7D+hy907gEeBxM+sG+oiCByHfk8ABYAq4092nIZriPLfMkP4p4PeANcDLZrbP3W8nCmKfNLMpYBTYEwKaxCD2lk19Fb0asxEpOrEFG5jttto3J+3elO0x4KYMx94P3J9NmSH9c8Dn0qR/AfjCYusuizc94wyMTMSyVE1SW30lIxPTjExMUVsZ69dXRHLoYpggIHkyODrJjMdzj03S7L02Z9W6ESkmCjaSM33norGUlhiDTUcINj0atxEpKgo2kjN956LVmNvqqmI7h1YREClOCjaSM8mWTZzdaMn10TRJQKS4KNhIziQXyGyL4cFpSecX41TLRqSYKNhIzvScHccM2mJs2VSVJ2isLlewESkyCjaSMz3D47TWVlKeiPdr1d6gGztFio2CjeTMmbPjdDTENzkgqb2+ip6zCjYixUTBRnKmZ3h8drZYnFY3VvPWkIKNSDFRsJGc6clTy2ZNYxWnhsbQqkMixUPBRnLC3TkznJ9gs7qxmompGQZHJ2M/l4jkhoKN5MTw+BRjkzO0xzjtOWlNUzUAp4bGYj+XiOSGgo3kRHLAPj/daCHYDCrYiBQLBRvJieQNnR311bGfa3UINqc1SUCkaCjYSE4kWzbtDfF3o61qjFpP6kYTKR4KNpITPWejX/wdeZj6XFWeoLWuUsFGpIjEGmzMbJeZHTSzbjO7O83+KjN7Iux/zsw2pey7J6QfNLPrFyrTzO4KaW5m7SnpZmafC/teNrNrYrzki1bP8DiJMqMlxgenpVrdWM1bGrMRKRqxBRszSwAPAjcA24CbzWzbnGy3Af3uvgX4LPBAOHYb0SOitwO7gIfMLLFAmd8Dfhl4Y845bgC2htcdwB/n8jolcubsBG11lZSVWV7Ot6axirfOKtiIFIs4WzY7gW53P+TuE8BeYPecPLuBx8L2U8B1ZmYhfa+7j7v7YaA7lJexTHf/sbsfSVOP3cCXPfJDoNnM1ub0SoWePN1jk7S6sZpTg5ogIFIs4gw264GjKe+PhbS0edx9ChgE2uY5Npsyl1IPWaZ8rR6QtLqxmt5z40xOz+TtnCKydJogEJjZHWbWZWZdPT09ha5O0ek5O56XyQFJa5qqcUcLcooUiTiDzXFgY8r7DSEtbR4zKweagN55js2mzKXUA3d/2N13uPuOjo6OBYqUVFPTM5w+O8bapvjvsUmavbFTM9JEikKcweYFYKuZbTazSqIB/845eTqBW8L2jcCzHq2u2AnsCbPVNhMN7j+fZZlzdQK/FWalvQ8YdPeTubhAifQMjzPjsKapJm/nXNscBZsTA6N5O6eILF15XAW7+5SZ3QU8DSSAR919v5ndB3S5eyfwCPC4mXUDfUTBg5DvSeAAMAXc6e7TEE1xnltmSP8U8HvAGuBlM9vn7rcD+4APE00yGAFujeuaL1YnwxTkfLZs1jdHge1Yv4KNSDGILdgAuPs+ol/2qWn3pmyPATdlOPZ+4P5sygzpnwM+lybdgTsXW3fJXnKNsjV5DDYN1RU011ZwrH8kb+cUkaXTBAFZtkK0bAA2tNSoZSNSJBRsZNlODY5SVV5GU01FXs+7oblWwUakSCjYyLKdHIxmokX34+ZP1LIZ0RM7RYqAgo0s26nBsbyO1yRtaKlhbHKG3nMTeT+3iCyOgo0sW9Syyd+056T1LbWAZqSJFAMFG1mWmRnnraHCtWwAzUgTKQIKNrIsZ4bHmZrxvM9Eg/PB5mifWjYiK52CjSzL0dCq2Bi6tPKpobqCtrpKjpw5l/dzi8jiKNjIsrzZF4JNa/7HbAAu66jjsIKNyIqnYCPLkuzC2lCAlg3A5vY6DinYiKx4CjayLG/2jbCqoYrqikRBzn9ZRz1nhscZGpssyPlFJDsKNrIsR/tGuKS1MK0aiFo2AId71LoRWckUbGRZjvWPsrGAweayZLBRV5rIiqZgI0s2MTXDicHCBptL2mopMzRuI7LCKdjIkp0YGMUdNrYUZiYaQFV5gg0ttfx9z3DB6iAiC1OwkSU7P+25cC0bgMtX1/PaqbMFrYOIzE/BRpbsUGhNJMdNCuWqtY0cOnOOscnpgtZDRDKLNdiY2S4zO2hm3WZ2d5r9VWb2RNj/nJltStl3T0g/aGbXL1SmmW0OZXSHMitD+ifMrMfMfhJet8d5zReT7p5hGqrL6WioKmg9rlzTyPSM8/pb6koTWaliCzZmlgAeBG4AtgE3m9m2OdluA/rdfQvwWeCBcOw2YA+wHdgFPGRmiQXKfAD4bCirP5Sd9IS7vzu8vhTD5V6Uuk8Ps2VVfd6fYzPXVWsbAHj15FBB6yEimcXZstkJdLv7IXefAPYCu+fk2Q08FrafAq6z6DfXbmCvu4+7+2GgO5SXtsxwzC+FMghl/np8lyYA3afPsaWjvtDV4NK2OmoqEhxQsBFZseIMNuuBoynvj4W0tHncfQoYBNrmOTZTehswEMpId66PmtnLZvaUmW1MV1kzu8PMusysq6enJ/urvEgNjkxyZnicrasLH2wSZcYVaxrUshFZwS6GCQJfBza5+7uAb3K+JXUBd3/Y3Xe4+46Ojo68VrAYdfdEs7+2rCp8sAHYtq6RAyeGmJnRI6JFVqI4g81xILUVsSGkpc1jZuVAE9A7z7GZ0nuB5lDGBedy9153Hw/pXwKuXdZVCRCN1wBs6WgocE0i79nYzNnxKbp1v43IihRnsHkB2BpmiVUSDfh3zsnTCdwStm8EnnV3D+l7wmy1zcBW4PlMZYZjvhXKIJT5vwHMbG3K+T4CvJrj67woHTw1THVFGesLeENnqh2bWgHoOtJf4JqISDqxBZswfnIX8DTRL/gn3X2/md1nZh8J2R4B2sysG/hd4O5w7H7gSeAA8NfAne4+nanMUNa/A343lNUWygb4lJntN7OXgE8Bn4jrmi8m+08MctXaRhJlhZ2JlrSprZa2ukpefEPBRmQlKl84y9K5+z5g35y0e1O2x4CbMhx7P3B/NmWG9ENEs9Xmpt8D3LPYuktmMzPO/hND/MZ75s73KBwz49pLW3jxjb5CV0VE0rgYJghIjr3RN8Lw+BQ/t76x0FW5wLWXtnCkd4Ses+MLZxaRvFKwkUV75fggANvXNRW4Jhd6/5Z2AL77uqaui6w0CjayaD9+c4Cq8jIuX70yZqIlbVvbSEdDFd86qGAjstIo2MiivXCkj3dvbKayfGV9fcrKjA9d3sG3D55manqm0NURkRQr67eFrHjD41PsPzHIzs2tha5KWv/oylUMjU3xozcHCl0VEUmhYCOL8qM3+plx+PlNKzPYfGBrO1XlZXz9pROFroqIpFCwkUX57us9VCSiacYrUUN1BddvX0PnSycYn9LzbURWCgUbWZRvHezhvZvbqKuK9RatZfmn16xncHSSZ189XeiqiEigYCNZO9o3QvfpYf7RlasKXZV5fWBrB2ubqvmz7x8pdFVEJFCwkaz95U9PAvDLV63sYJMoM27/wGU8d7iPF45oRQGRlUDBRrL2tR8f5z2XNHNpW12hq7Kgm3dupLWukv/2zGtE67SKSCEp2EhWfnpskJ+dOrui1kObT21lOZ/6pS18r7uXTs1MEyk4BRvJypf+7hD1VeX8epEEG4CP/8Imrt7QxH1fP8CJgdFCV0fkoqZgIws61DPMN14+yZ6f30hjdUWhq5O1RJnxX//Z1UxMzXDbY10MjU0WukoiF62VO39VVgR35/f/8lVqKhL89j98R6Grs2hbVjXw+X/+Hm5/rIt/9sUf8Ce/tYONrbWLLufM8DivnTrL66eHOTk4Ru/wOGfHpgAoK4Pm2ko66qvY2FrLtrWNbFlVv+KW8xEpJAUbmdcTLxzl2Z+d5j/+2lV0NFQVujpL8qErVvFnt+7kk//jRX71s9/hX33wMn7zvZewqrE6bf7+cxO8dGyAl44O8tKxAV4+NsCZ4YnZ/RUJo62uisaacgxj2p3+cxP0nrswzzvXN/H+Le38g3e0c82lzVSVJ2K/VpGVyuKcqWNmu4A/AhLAl9z9D+bsrwK+DFwL9AIfc/cjYd89wG3ANPApd396vjLD46P3Ej2l80Xg4+4+Md85MtmxY4d3dXUt+/qL3bM/e4vffvxF3ndZG392684V81TOpTo+MMp9X9/P0/vfAuDy1fVsaqujvrqc8ckZes6Oc6T3HKfD83DMYEtHPe/a0My2dY1csbqBy1fX09FQhdnbP4uJqRne7BvhwMkh9p8Y5LlDfbx8bIAZh5qKBO+9rJUPbO3gg1vb2bKqPm0ZsjQDIxPsPzHEK8cH6T49TM/wOH3nJpiecRJlRnVFgjWN1axtqmbr6gauWtvAllX1+gMgx8zsRXffkXZfXMHGzBLAa8CvAMeAF4Cb3f1ASp7fAd7l7v/azPYAv+HuHzOzbcD/JHry5jrgGeDycFjaMs3sSeCr7r7XzL4IvOTuf5zpHPPV/WIPNiMTU3zx24f4wrOvs31dE//j9vfSVFM8YzUL+fueYf76lVN0Henj+MAo58anqaooo7W2kk3tdWxZVc+7NjTxzvVNNCxzjGpobJLnDvXxve4zfOf1Hg71nANgTWM1H9jazi9ujVo+xdpqzDd3562hcV4NAf2V40O8cmKQY/3nJ4CsaqhiVWMVbXVVVCSMGY8WkH1raIyTg2NMTEUrgpeXGVtXN/DO9Y383Pomtq9rYtvaRmoqFYCWqlDB5heAz7j79eH9PQDu/v+m5Hk65PmBmZUDp4AO4O7UvMl84bC3lQn8AdADrHH3qdRzZzqHz3PhF1OwcXcGRyc5fTb6H/j5w33s++lJ+kcm+fV3r+P3f+Od1K/gpWmKzbH+Ef7u9TN89/Uz/F33GQZHo0kLqxqqZltP61tqWNdUw9rmapprK6mvKqe+qrzoW5bZGJ+a5uzYFMNjU/SNTHBiYJQTA6Mc7x/l9dPDvHpyiP6R8xM9NrfXsX1dFCx+bl0T29c10lJXmbH86Rnn8JlzvHpyKLRAo9ZQX+gCLTPYsqqe7euauLStlnXNNWxorqG9oYqG6nIaqyuorUyoVZrBfMEmzt8i64GjKe+PAe/NlCcEiUGibrD1wA/nHJucc5uuzDZgwN2n0uTPdI4zS76yDL79Wg//+RsHZm8i9Nn/zP7A3VO2k/v8/PacELhgfuYel25fmjJC2ujENFMz509aU5HguqtWcev7N3HtpStzZeditqGllj07L2HPzkuYnnFeOT7IC0f6OHByiAMnhvh+dy8TGZ7FU1uZoCJRRnmZkSiz6GfCKC8rI9vffdn+iszml2nyO+Qebc/4+e9mMs2BGY/SZsL/ENH2+WNn3MFhfGom47U3VJezub2OX922hqvWNnDV2ka2rWtcdMszUWZsWVXPllX1/JOr181ex8nBMV45PsgrIfj84O97+YsfH89YRnV5GYkyoyJx/md5wigzS/8ZZ/g4M33K6T7/fIW3j/38Rm7/wGU5L1d/sgZmdgdwB8All1yypDLqq8q5Ivn0Sjv/I/nFSX5ZzFK3L9yHQfLraheUkdw+v89SD8om/5xzAtRUJmivr6K9vpKtq6IxifKEZlHlQ6LMuHpjM1dvbJ5Nm5lxzpwb58TAGCcHRhkam+Ts2FT01/74FNMzztTMTPRz2pmecSZnPKtVErLuw8gio+MYFr6HRpmd/65b+A6bEdKNsjJgTlq0ff77WVWeoKG6fPbVVFPBuuYa1jXXxDrl3sxmz/Or29fMpo9PTXNqcIzj/aP0npsI/w6TDI1NMj45w9SMMzkd/VtMTjvTMzNMp/nsMv3bZPyY05WR/b/esrXXx9OlG2ewOQ5sTHm/IaSly3MsdHE1EQ3iz3dsuvReoNnMykPrJjV/pnNcwN0fBh6GqBttUVcaXHtpy4pdel+KQ1mZsaqhmlUN1bw7JQhJ/lWVJ7i0ra4olmcqBnH+CfsCsNXMNptZJbAH6JyTpxO4JWzfCDwbxlI6gT1mVhVmmW0Fns9UZjjmW6EMQpn/e4FziIhInsTWsgnjI3cBTxNNU37U3feb2X1Al7t3Ao8Aj5tZN9BHFDwI+Z4EDgBTwJ3uPg2Qrsxwyn8H7DWz3wd+HMom0zlERCR/Yr3PplhdTLPRRERyZb7ZaBoJFhGR2CnYiIhI7BRsREQkdgo2IiISOwUbERGJnWajpWFmPcAbKUntxLC8TYxU3/gUU11B9Y2b6nuhS929I90OBZssmFlXpul8K5HqG59iqiuovnFTfbOnbjQREYmdgo2IiMROwSY7Dxe6Aouk+sanmOoKqm/cVN8sacxGRERip5aNiIjE7qIMNmZ2k5ntN7MZM9sxZ989ZtZtZgfN7PqU9F0hrdvM7k5J32xmz4X0J8KjDwiPR3gipD9nZptyVPfPmNlxM/tJeH0413XPl0z1KgQzO2JmPw2faVdIazWzb5rZ6+FnS0g3M/tcqPfLZnZNSjm3hPyvm9ktmc63hPo9amanzeyVlLSc1c/Mrg3X3x2OXdaDITPUd0V+d81so5l9y8wOhN8L/1dIX5Gf7zz1XZGf7yx3v+hewFXAFcDfAjtS0rcBLwFVwGbg74keZZAI25cBlSHPtnDMk8CesP1F4JNh+3eAL4btPcATOar7Z4D/O016zuqep3+DjPUq0HfiCNA+J+0PgbvD9t3AA2H7w8BfET2c8n3AcyG9FTgUfraE7ZYc1e+DwDXAK3HUj+h5Ue8Lx/wVcEMM9V2R311gLXBN2G4AXgt1WpGf7zz1XZGfb/J1UbZs3P1Vdz+YZtduYK+7j7v7YaAb2Ble3e5+yN0ngL3A7vDXyS8BT4XjHwN+PaWsx8L2U8B1y/1rcQG5rHs+pK1XHs+fjdR/w7n/tl/2yA+JnhK7Frge+Ka797l7P/BNYFcuKuLu3yF6HlPO6xf2Nbr7Dz367fJllvldyFDfTAr63XX3k+7+o7B9FngVWM8K/XznqW8mK+J3w0UZbOaxHjia8v5YSMuU3gYMePQo6tT0C8oK+wdD/ly4KzTfH0027XNc93zIVK9CceD/mNmLZnZHSFvt7ifD9ilgddhe7Gcdl1zVb33YnpsehxX93bWou/s9wHMUwec7p76wgj/fkg02ZvaMmb2S5rXS/np+mwXq/sfAO4B3AyeB/1rIupaQX3T3a4AbgDvN7IOpO8NfpCt26uZKr1+wor+7ZlYP/C/g37j7UOq+lfj5pqnviv58Y3ssdKG5+y8v4bDjwMaU9xtCGhnSe4ma0OXhr4DU/MmyjplZOdAU8ues7mb2J8A3Yqh7PsxX37xz9+Ph52kz+wuiLoa3zGytu58MXSGnQ/ZMdT8OfGhO+t/GWO1c1e942J6bP6fc/a3k9kr77ppZBdEv7q+4+1dD8or9fNPVdyV/voQKXrQv3j5BYDsXDqQdIhpEKw/bmzk/kLY9HPPnXDiQ9jth+04unCDwZI7qvDZl+9NEfbE5rXuePvuM9SrA96AOaEjZ/j7RWMt/4cIB4j8M27/GhQPEz4f0VuAw0eBwS9huzWE9N3HhgHvO6sfbB7A/HEN9V+R3N1zzl4H/Nid9RX6+89R3RX6+s3XK1f8IxfQCfoOoH3IceAt4OmXffyCaoXGQlBkjRDNQXgv7/kNK+mXhi9Qd/oGqQnp1eN8d9l+Wo7o/DvwUeBnonPMFy0nd8/jvkLZeBfg+XBb+R3sJ2J+sC1Hf9d8ArwPPpPziMODBUO+fcuEfLP8yfJ7dwK05rOP/JOoamQzf3dtyWT9gB/BKOOYLhBu+c1zfFfndBX6RqIvsZeAn4fXhlfr5zlPfFfn5Jl9aQUBERGJXshMERERk5VCwERGR2CnYiIhI7BRsREQkdgo2IiISOwUbERGJnYKNiIjETsFGRERi9/8DPpB3ByO1SZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "classification_value.plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(classification_value[classification_value<1000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                     0.0   \n",
       "1           1    108590              1                     0.0   \n",
       "2           1      5000              0                     0.0   \n",
       "3           1      6692              1                     0.0   \n",
       "4           1    142590              1                     0.0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                     0.0   \n",
       "34295       1      5000              0                     0.0   \n",
       "34296       1      5000              0                     0.0   \n",
       "34297       1      5000              1                     0.0   \n",
       "34298       1  36500179              0                     0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                       1.0                   0.0                  0.0   \n",
       "1                       0.0                   0.0                  1.0   \n",
       "2                       0.0                   0.0                  0.0   \n",
       "3                       0.0                   0.0                  1.0   \n",
       "4                       0.0                   0.0                  1.0   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                   0.0                   0.0                  0.0   \n",
       "34295                   0.0                   0.0                  0.0   \n",
       "34296                   0.0                   0.0                  1.0   \n",
       "34297                   0.0                   0.0                  0.0   \n",
       "34298                   0.0                   0.0                  1.0   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                      0.0                  0.0                  0.0  ...   \n",
       "1                      0.0                  0.0                  0.0  ...   \n",
       "2                      0.0                  1.0                  0.0  ...   \n",
       "3                      0.0                  0.0                  0.0  ...   \n",
       "4                      0.0                  0.0                  0.0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                  1.0                  0.0                  0.0  ...   \n",
       "34295                  1.0                  0.0                  0.0  ...   \n",
       "34296                  0.0                  0.0                  0.0  ...   \n",
       "34297                  0.0                  1.0                  0.0  ...   \n",
       "34298                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    1.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     1.0                       0.0   \n",
       "4                    0.0                     0.0                       1.0   \n",
       "...                  ...                     ...                       ...   \n",
       "34294                0.0                     0.0                       0.0   \n",
       "34295                0.0                     0.0                       0.0   \n",
       "34296                0.0                     0.0                       0.0   \n",
       "34297                0.0                     0.0                       0.0   \n",
       "34298                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "...                   ...               ...                     ...   \n",
       "34294                 0.0               0.0                     0.0   \n",
       "34295                 0.0               0.0                     0.0   \n",
       "34296                 0.0               0.0                     0.0   \n",
       "34297                 0.0               0.0                     0.0   \n",
       "34298                 0.0               1.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "...                ...                ...                       ...   \n",
       "34294              0.0                0.0                       1.0   \n",
       "34295              0.0                0.0                       1.0   \n",
       "34296              0.0                0.0                       1.0   \n",
       "34297              0.0                0.0                       1.0   \n",
       "34298              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "34294                       0.0  \n",
       "34295                       0.0  \n",
       "34296                       0.0  \n",
       "34297                       0.0  \n",
       "34298                       0.0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_df = pd.get_dummies(application_df, dtype=float)\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df.IS_SUCCESSFUL.values\n",
    "X = application_df.drop('IS_SUCCESSFUL', axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 80)                3520      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,981\n",
      "Trainable params: 5,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len( X_train_scaled[0])\n",
    "hidden_nodes_layer1=80\n",
    "hidden_nodes_layer2=30\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "684/684 [==============================] - 6s 6ms/step - loss: 0.5711 - accuracy: 0.7197 - recall: 0.7731 - val_loss: 0.5494 - val_accuracy: 0.7380 - val_recall: 0.7586\n",
      "Epoch 2/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5574 - accuracy: 0.7284 - recall: 0.7842 - val_loss: 0.5477 - val_accuracy: 0.7313 - val_recall: 0.8009\n",
      "Epoch 3/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5540 - accuracy: 0.7286 - recall: 0.7915 - val_loss: 0.5513 - val_accuracy: 0.7323 - val_recall: 0.7700\n",
      "Epoch 4/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5528 - accuracy: 0.7289 - recall: 0.7913 - val_loss: 0.5481 - val_accuracy: 0.7357 - val_recall: 0.7591\n",
      "Epoch 5/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5512 - accuracy: 0.7287 - recall: 0.7937 - val_loss: 0.5466 - val_accuracy: 0.7344 - val_recall: 0.7641\n",
      "Epoch 6/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5501 - accuracy: 0.7294 - recall: 0.7894 - val_loss: 0.5487 - val_accuracy: 0.7292 - val_recall: 0.8163\n",
      "Epoch 7/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5494 - accuracy: 0.7314 - recall: 0.7906 - val_loss: 0.5439 - val_accuracy: 0.7339 - val_recall: 0.7646\n",
      "Epoch 8/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5481 - accuracy: 0.7327 - recall: 0.7910 - val_loss: 0.5465 - val_accuracy: 0.7359 - val_recall: 0.7670\n",
      "Epoch 9/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5475 - accuracy: 0.7317 - recall: 0.7925 - val_loss: 0.5445 - val_accuracy: 0.7370 - val_recall: 0.7566\n",
      "Epoch 10/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5471 - accuracy: 0.7323 - recall: 0.7941 - val_loss: 0.5426 - val_accuracy: 0.7352 - val_recall: 0.7715\n",
      "Epoch 11/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5467 - accuracy: 0.7324 - recall: 0.7887 - val_loss: 0.5434 - val_accuracy: 0.7359 - val_recall: 0.7705\n",
      "Epoch 12/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5464 - accuracy: 0.7319 - recall: 0.7937 - val_loss: 0.5474 - val_accuracy: 0.7344 - val_recall: 0.7626\n",
      "Epoch 13/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5459 - accuracy: 0.7330 - recall: 0.7916 - val_loss: 0.5438 - val_accuracy: 0.7372 - val_recall: 0.7790\n",
      "Epoch 14/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5458 - accuracy: 0.7331 - recall: 0.7919 - val_loss: 0.5438 - val_accuracy: 0.7370 - val_recall: 0.7631\n",
      "Epoch 15/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5455 - accuracy: 0.7349 - recall: 0.7889 - val_loss: 0.5465 - val_accuracy: 0.7352 - val_recall: 0.7725\n",
      "Epoch 16/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5448 - accuracy: 0.7348 - recall: 0.7996 - val_loss: 0.5476 - val_accuracy: 0.7344 - val_recall: 0.7491\n",
      "Epoch 17/100\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 0.5448 - accuracy: 0.7347 - recall: 0.7927 - val_loss: 0.5431 - val_accuracy: 0.7372 - val_recall: 0.7596\n",
      "Epoch 18/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5444 - accuracy: 0.7335 - recall: 0.7953 - val_loss: 0.5445 - val_accuracy: 0.7352 - val_recall: 0.7840\n",
      "Epoch 19/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5441 - accuracy: 0.7348 - recall: 0.7907 - val_loss: 0.5460 - val_accuracy: 0.7344 - val_recall: 0.7601\n",
      "Epoch 20/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5438 - accuracy: 0.7356 - recall: 0.7935 - val_loss: 0.5456 - val_accuracy: 0.7344 - val_recall: 0.7680\n",
      "Epoch 21/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5432 - accuracy: 0.7328 - recall: 0.7939 - val_loss: 0.5450 - val_accuracy: 0.7334 - val_recall: 0.7656\n",
      "Epoch 22/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5430 - accuracy: 0.7359 - recall: 0.7949 - val_loss: 0.5475 - val_accuracy: 0.7289 - val_recall: 0.7899\n",
      "Epoch 23/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5425 - accuracy: 0.7347 - recall: 0.7995 - val_loss: 0.5452 - val_accuracy: 0.7354 - val_recall: 0.7506\n",
      "Epoch 24/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5427 - accuracy: 0.7363 - recall: 0.7924 - val_loss: 0.5450 - val_accuracy: 0.7341 - val_recall: 0.7506\n",
      "Epoch 25/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5423 - accuracy: 0.7353 - recall: 0.7924 - val_loss: 0.5441 - val_accuracy: 0.7362 - val_recall: 0.7760\n",
      "Epoch 26/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5425 - accuracy: 0.7358 - recall: 0.7968 - val_loss: 0.5430 - val_accuracy: 0.7349 - val_recall: 0.7725\n",
      "Epoch 27/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5415 - accuracy: 0.7365 - recall: 0.7950 - val_loss: 0.5461 - val_accuracy: 0.7310 - val_recall: 0.7939\n",
      "Epoch 28/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5419 - accuracy: 0.7349 - recall: 0.7907 - val_loss: 0.5440 - val_accuracy: 0.7341 - val_recall: 0.7621\n",
      "Epoch 29/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7362 - recall: 0.7934 - val_loss: 0.5446 - val_accuracy: 0.7344 - val_recall: 0.7651\n",
      "Epoch 30/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5409 - accuracy: 0.7355 - recall: 0.7945 - val_loss: 0.5435 - val_accuracy: 0.7357 - val_recall: 0.7715\n",
      "Epoch 31/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5409 - accuracy: 0.7366 - recall: 0.7936 - val_loss: 0.5439 - val_accuracy: 0.7365 - val_recall: 0.7889\n",
      "Epoch 32/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5410 - accuracy: 0.7362 - recall: 0.7923 - val_loss: 0.5437 - val_accuracy: 0.7365 - val_recall: 0.7785\n",
      "Epoch 33/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5406 - accuracy: 0.7365 - recall: 0.7958 - val_loss: 0.5459 - val_accuracy: 0.7328 - val_recall: 0.7581\n",
      "Epoch 34/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5406 - accuracy: 0.7364 - recall: 0.7951 - val_loss: 0.5438 - val_accuracy: 0.7372 - val_recall: 0.7621\n",
      "Epoch 35/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5406 - accuracy: 0.7360 - recall: 0.7934 - val_loss: 0.5402 - val_accuracy: 0.7370 - val_recall: 0.7700\n",
      "Epoch 36/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5405 - accuracy: 0.7365 - recall: 0.7963 - val_loss: 0.5445 - val_accuracy: 0.7349 - val_recall: 0.7690\n",
      "Epoch 37/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5396 - accuracy: 0.7373 - recall: 0.7929 - val_loss: 0.5450 - val_accuracy: 0.7357 - val_recall: 0.7710\n",
      "Epoch 38/100\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 0.5394 - accuracy: 0.7367 - recall: 0.7917 - val_loss: 0.5478 - val_accuracy: 0.7352 - val_recall: 0.7695\n",
      "Epoch 39/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5404 - accuracy: 0.7360 - recall: 0.7897 - val_loss: 0.5421 - val_accuracy: 0.7346 - val_recall: 0.7651\n",
      "Epoch 40/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5394 - accuracy: 0.7381 - recall: 0.7993 - val_loss: 0.5430 - val_accuracy: 0.7359 - val_recall: 0.7661\n",
      "Epoch 41/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5395 - accuracy: 0.7382 - recall: 0.7953 - val_loss: 0.5441 - val_accuracy: 0.7328 - val_recall: 0.7666\n",
      "Epoch 42/100\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 0.5387 - accuracy: 0.7379 - recall: 0.7955 - val_loss: 0.5431 - val_accuracy: 0.7385 - val_recall: 0.7795\n",
      "Epoch 43/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5392 - accuracy: 0.7370 - recall: 0.7953 - val_loss: 0.5442 - val_accuracy: 0.7354 - val_recall: 0.7661\n",
      "Epoch 44/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5390 - accuracy: 0.7380 - recall: 0.7943 - val_loss: 0.5448 - val_accuracy: 0.7349 - val_recall: 0.7725\n",
      "Epoch 45/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5391 - accuracy: 0.7382 - recall: 0.7899 - val_loss: 0.5464 - val_accuracy: 0.7323 - val_recall: 0.7566\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5382 - accuracy: 0.7383 - recall: 0.7961 - val_loss: 0.5443 - val_accuracy: 0.7346 - val_recall: 0.7666\n",
      "Epoch 47/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5383 - accuracy: 0.7382 - recall: 0.7942 - val_loss: 0.5435 - val_accuracy: 0.7344 - val_recall: 0.7641\n",
      "Epoch 48/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5383 - accuracy: 0.7390 - recall: 0.7944 - val_loss: 0.5463 - val_accuracy: 0.7357 - val_recall: 0.7745\n",
      "Epoch 49/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5383 - accuracy: 0.7383 - recall: 0.7965 - val_loss: 0.5462 - val_accuracy: 0.7352 - val_recall: 0.7675\n",
      "Epoch 50/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5382 - accuracy: 0.7390 - recall: 0.7924 - val_loss: 0.5474 - val_accuracy: 0.7359 - val_recall: 0.7855\n",
      "Epoch 51/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5379 - accuracy: 0.7380 - recall: 0.7937 - val_loss: 0.5458 - val_accuracy: 0.7349 - val_recall: 0.7770\n",
      "Epoch 52/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5378 - accuracy: 0.7386 - recall: 0.7921 - val_loss: 0.5468 - val_accuracy: 0.7346 - val_recall: 0.7611\n",
      "Epoch 53/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5377 - accuracy: 0.7373 - recall: 0.7925 - val_loss: 0.5457 - val_accuracy: 0.7357 - val_recall: 0.7631\n",
      "Epoch 54/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5376 - accuracy: 0.7398 - recall: 0.7959 - val_loss: 0.5445 - val_accuracy: 0.7365 - val_recall: 0.7700\n",
      "Epoch 55/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5377 - accuracy: 0.7382 - recall: 0.7940 - val_loss: 0.5469 - val_accuracy: 0.7344 - val_recall: 0.7651\n",
      "Epoch 56/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5375 - accuracy: 0.7386 - recall: 0.7958 - val_loss: 0.5469 - val_accuracy: 0.7349 - val_recall: 0.7670\n",
      "Epoch 57/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5375 - accuracy: 0.7391 - recall: 0.7961 - val_loss: 0.5464 - val_accuracy: 0.7346 - val_recall: 0.7666\n",
      "Epoch 58/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5374 - accuracy: 0.7389 - recall: 0.7929 - val_loss: 0.5466 - val_accuracy: 0.7346 - val_recall: 0.7715\n",
      "Epoch 59/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7390 - recall: 0.7959 - val_loss: 0.5444 - val_accuracy: 0.7346 - val_recall: 0.7670\n",
      "Epoch 60/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5369 - accuracy: 0.7392 - recall: 0.7982 - val_loss: 0.5457 - val_accuracy: 0.7370 - val_recall: 0.7750\n",
      "Epoch 61/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5369 - accuracy: 0.7391 - recall: 0.7965 - val_loss: 0.5470 - val_accuracy: 0.7354 - val_recall: 0.7621\n",
      "Epoch 62/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7390 - recall: 0.7950 - val_loss: 0.5454 - val_accuracy: 0.7349 - val_recall: 0.7670\n",
      "Epoch 63/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7389 - recall: 0.7949 - val_loss: 0.5472 - val_accuracy: 0.7341 - val_recall: 0.7636\n",
      "Epoch 64/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5365 - accuracy: 0.7399 - recall: 0.7982 - val_loss: 0.5461 - val_accuracy: 0.7349 - val_recall: 0.7641\n",
      "Epoch 65/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5365 - accuracy: 0.7390 - recall: 0.7928 - val_loss: 0.5483 - val_accuracy: 0.7334 - val_recall: 0.7651\n",
      "Epoch 66/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5362 - accuracy: 0.7387 - recall: 0.7959 - val_loss: 0.5503 - val_accuracy: 0.7349 - val_recall: 0.7636\n",
      "Epoch 67/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5366 - accuracy: 0.7390 - recall: 0.7920 - val_loss: 0.5458 - val_accuracy: 0.7349 - val_recall: 0.7646\n",
      "Epoch 68/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7393 - recall: 0.7967 - val_loss: 0.5468 - val_accuracy: 0.7357 - val_recall: 0.7720\n",
      "Epoch 69/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5360 - accuracy: 0.7391 - recall: 0.7975 - val_loss: 0.5492 - val_accuracy: 0.7359 - val_recall: 0.7591\n",
      "Epoch 70/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5362 - accuracy: 0.7389 - recall: 0.7961 - val_loss: 0.5471 - val_accuracy: 0.7339 - val_recall: 0.7661\n",
      "Epoch 71/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5357 - accuracy: 0.7388 - recall: 0.7942 - val_loss: 0.5468 - val_accuracy: 0.7375 - val_recall: 0.7710\n",
      "Epoch 72/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5356 - accuracy: 0.7391 - recall: 0.7963 - val_loss: 0.5481 - val_accuracy: 0.7362 - val_recall: 0.7690\n",
      "Epoch 73/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5362 - accuracy: 0.7390 - recall: 0.7954 - val_loss: 0.5477 - val_accuracy: 0.7370 - val_recall: 0.7641\n",
      "Epoch 74/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5356 - accuracy: 0.7391 - recall: 0.7924 - val_loss: 0.5511 - val_accuracy: 0.7344 - val_recall: 0.7690\n",
      "Epoch 75/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5359 - accuracy: 0.7390 - recall: 0.7974 - val_loss: 0.5478 - val_accuracy: 0.7362 - val_recall: 0.7680\n",
      "Epoch 76/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7393 - recall: 0.7961 - val_loss: 0.5489 - val_accuracy: 0.7352 - val_recall: 0.7705\n",
      "Epoch 77/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5355 - accuracy: 0.7400 - recall: 0.7961 - val_loss: 0.5483 - val_accuracy: 0.7362 - val_recall: 0.7700\n",
      "Epoch 78/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5356 - accuracy: 0.7401 - recall: 0.7952 - val_loss: 0.5516 - val_accuracy: 0.7344 - val_recall: 0.7745\n",
      "Epoch 79/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5351 - accuracy: 0.7391 - recall: 0.7971 - val_loss: 0.5507 - val_accuracy: 0.7357 - val_recall: 0.7641\n",
      "Epoch 80/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5350 - accuracy: 0.7403 - recall: 0.7961 - val_loss: 0.5460 - val_accuracy: 0.7365 - val_recall: 0.7675\n",
      "Epoch 81/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5353 - accuracy: 0.7399 - recall: 0.7965 - val_loss: 0.5497 - val_accuracy: 0.7354 - val_recall: 0.7770\n",
      "Epoch 82/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5348 - accuracy: 0.7391 - recall: 0.7987 - val_loss: 0.5578 - val_accuracy: 0.7359 - val_recall: 0.7446\n",
      "Epoch 83/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5352 - accuracy: 0.7402 - recall: 0.7949 - val_loss: 0.5480 - val_accuracy: 0.7341 - val_recall: 0.7680\n",
      "Epoch 84/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5349 - accuracy: 0.7397 - recall: 0.7984 - val_loss: 0.5510 - val_accuracy: 0.7362 - val_recall: 0.7685\n",
      "Epoch 85/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5350 - accuracy: 0.7405 - recall: 0.7970 - val_loss: 0.5492 - val_accuracy: 0.7352 - val_recall: 0.7685\n",
      "Epoch 86/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5346 - accuracy: 0.7402 - recall: 0.7973 - val_loss: 0.5479 - val_accuracy: 0.7378 - val_recall: 0.7685\n",
      "Epoch 87/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5353 - accuracy: 0.7398 - recall: 0.7973 - val_loss: 0.5483 - val_accuracy: 0.7370 - val_recall: 0.7710\n",
      "Epoch 88/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5347 - accuracy: 0.7399 - recall: 0.7981 - val_loss: 0.5490 - val_accuracy: 0.7372 - val_recall: 0.7710\n",
      "Epoch 89/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5343 - accuracy: 0.7398 - recall: 0.7970 - val_loss: 0.5499 - val_accuracy: 0.7362 - val_recall: 0.7705\n",
      "Epoch 90/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5346 - accuracy: 0.7399 - recall: 0.7982 - val_loss: 0.5505 - val_accuracy: 0.7357 - val_recall: 0.7705\n",
      "Epoch 91/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5344 - accuracy: 0.7398 - recall: 0.7986 - val_loss: 0.5488 - val_accuracy: 0.7354 - val_recall: 0.7661\n",
      "Epoch 92/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5346 - accuracy: 0.7386 - recall: 0.7979 - val_loss: 0.5507 - val_accuracy: 0.7362 - val_recall: 0.7651\n",
      "Epoch 93/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5346 - accuracy: 0.7401 - recall: 0.7966 - val_loss: 0.5501 - val_accuracy: 0.7362 - val_recall: 0.7670\n",
      "Epoch 94/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5343 - accuracy: 0.7404 - recall: 0.7954 - val_loss: 0.5510 - val_accuracy: 0.7354 - val_recall: 0.7641\n",
      "Epoch 95/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5343 - accuracy: 0.7399 - recall: 0.7987 - val_loss: 0.5507 - val_accuracy: 0.7336 - val_recall: 0.7636\n",
      "Epoch 96/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5345 - accuracy: 0.7397 - recall: 0.7950 - val_loss: 0.5504 - val_accuracy: 0.7362 - val_recall: 0.7656\n",
      "Epoch 97/100\n",
      "684/684 [==============================] - 3s 4ms/step - loss: 0.5343 - accuracy: 0.7405 - recall: 0.7990 - val_loss: 0.5511 - val_accuracy: 0.7339 - val_recall: 0.7661\n",
      "Epoch 98/100\n",
      "684/684 [==============================] - 4s 5ms/step - loss: 0.5342 - accuracy: 0.7401 - recall: 0.7978 - val_loss: 0.5497 - val_accuracy: 0.7367 - val_recall: 0.7651\n",
      "Epoch 99/100\n",
      "684/684 [==============================] - 4s 6ms/step - loss: 0.5337 - accuracy: 0.7407 - recall: 0.7976 - val_loss: 0.5501 - val_accuracy: 0.7359 - val_recall: 0.7675\n",
      "Epoch 100/100\n",
      "684/684 [==============================] - 3s 5ms/step - loss: 0.5342 - accuracy: 0.7398 - recall: 0.8011 - val_loss: 0.5506 - val_accuracy: 0.7346 - val_recall: 0.7591\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled,y_train,validation_split=0.15, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5702 - accuracy: 0.7263 - recall: 0.7730\n",
      "Loss: 0.5702385306358337, Accuracy: 0.7262973785400391\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy, model_Recall= nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "                                               \n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
